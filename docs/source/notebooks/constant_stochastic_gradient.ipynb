{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Stochastic Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Can we approximately sample from a Bayesian posterior distribution if we are only allowed to touch a small mini-batch of data-items for every sample we generate ?\n",
    "```\n",
    "\n",
    "Based on results from a recent paper, a simple implementation of constant stochastic gradient is presented as an approximate bayesian sampling algorithm. The objective of the notebook is to compare the approximate distribution to iterates from NUTS and SGFS.\n",
    "\n",
    "Ref: https://arxiv.org/abs/1704.04289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import theano\n",
    "import numpy as np\n",
    "rng = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import theano.tensor as tt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a regression on a protein dataset that is used to show results in Figure 1. \n",
    "It is a multivariate regression problem on the Protein Structure Properties dataset available at the [uci repo](https://archive.ics.uci.edu/ml/datasets/Physicochemical+Properties+of+Protein+Tertiary+Structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00265/CASP.csv --directory-prefix=/tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/tmp/CASP.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-82570260cd56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/CASP.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mq_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mq_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'F1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F7'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F9'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/tmp/CASP.csv' does not exist"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('/tmp/CASP.csv', delimiter=',')\n",
    "data = (raw_data - raw_data.mean())/raw_data.std()\n",
    "q_size = data.shape[1]-1\n",
    "q_name = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_N = data.size/len(data.columns)\n",
    "train_test_split = 0.95\n",
    "ixs = rng.randint(data_N, size=int(data_N*train_test_split))\n",
    "neg_ixs = list(set(range(data_N)) - set(ixs))\n",
    "train_df = data.iloc[ixs]\n",
    "test_df = data.iloc[neg_ixs]\n",
    "\n",
    "N = train_df.size / len(train_df.columns)\n",
    "n_test = test_df.size / len(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df[q_name].as_matrix()\n",
    "train_Y = train_df['RMSD'].as_matrix()\n",
    "\n",
    "test_X = test_df[q_name].as_matrix()\n",
    "test_Y = test_df['RMSD'].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try regression models from sklearn to construct the best pymc3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "sklearn_regression_model = {\n",
    "    'Ridge': linear_model.Ridge (alpha = .5),\n",
    "    'Lasso': linear_model.Lasso(alpha = 0.1),\n",
    "    'BayesianRidge': linear_model.BayesianRidge(),\n",
    "    'OLS': linear_model.LinearRegression(),\n",
    "}\n",
    "for name, reg in sklearn_regression_model.items():\n",
    "    reg.fit(train_X, train_Y) \n",
    "    pred = reg.predict(test_X)\n",
    "    diff = pred-test_Y\n",
    "    print('The {} Mean Absolute Error is {}'.format(name, np.sum(np.abs(diff))/test_Y.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS fit has the minimum mean absolute error so we will select normal priors on the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = theano.shared(train_X, name='X')\n",
    "model_output = theano.shared(train_Y, name='Y')\n",
    "\n",
    "with pm.Model() as model:\n",
    "    b0 = pm.Normal(\"Intercept\", mu=0.0, sd=1.0)\n",
    "    b1 = pm.Normal(\"Slope\", mu=0.0, shape=(q_size,))\n",
    "    std = pm.HalfNormal(\"std\", sd=1.0)\n",
    "\n",
    "    mu = b0 + theano.dot(model_input, b1)      \n",
    "    y_obs = pm.Normal(\"y_obs\", mu=mu, sd=std, observed=model_output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    start = pm.find_MAP()\n",
    "    \n",
    "map_pred = np.matmul(test_X, start['Slope'] ) + start['Intercept']\n",
    "map_diff = map_pred-test_Y\n",
    "print('The {} Mean Absolute Error is {}'.format(\"OLS MAP Estimate\", np.sum(np.abs(map_diff))/test_Y.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will to proceed perform bayesian sampling to calculate the posterior on the OLS pymc3 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make model and minibatches input for the stochastic sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = 10000\n",
    "with model:\n",
    "    nuts_trace = pm.sample(draws=draws, tune=500)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator that returns mini-batches in each iteration\n",
    "def create_minibatches(batch_size):\n",
    "    while True:\n",
    "        # Return random data samples of set size 100 each iteration\n",
    "        ixs = rng.randint(N, size=batch_size)\n",
    "        yield (train_X[ixs], train_Y[ixs])\n",
    "\n",
    "# Tensors and RV that wil l be using mini-batches\n",
    "batch_size = 50\n",
    "minibatches = create_minibatches(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = theano.shared(train_X, name='X')\n",
    "model_output = theano.shared(train_Y, name='Y')\n",
    "\n",
    "with pm.Model() as model:\n",
    "    b0 = pm.Normal(\"Intercept\", mu=0.0, sd=1.0)\n",
    "    b1 = pm.Normal(\"Slope\", mu=0.0, shape=(q_size,))\n",
    "    std = pm.HalfNormal(\"std\", sd=1.0)\n",
    "\n",
    "    mu = b0 + theano.dot(model_input, b1)      \n",
    "    y_obs = pm.Normal(\"y_obs\", mu=mu, sd=std, observed=model_output) \n",
    "    \n",
    "minibatch_tensors = [model_input, model_output]\n",
    "\n",
    "draws = 10000*5\n",
    "with model:\n",
    "    csg_step_method = pm.step_methods.CSG(vars=model.vars,\n",
    "                                          model=model,\n",
    "                                          total_size=N, \n",
    "                                          batch_size=batch_size,\n",
    "                                          minibatches=minibatches, \n",
    "                                          minibatch_tensors=minibatch_tensors) \n",
    "    csg_trace = pm.sample(draws=draws, step=csg_step_method, tune=500, init='map')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = theano.shared(train_X, name='X')\n",
    "model_output = theano.shared(train_Y, name='Y')\n",
    "\n",
    "with pm.Model() as model:\n",
    "    b0 = pm.Normal(\"Intercept\", mu=0.0, sd=1.0)\n",
    "    b1 = pm.Normal(\"Slope\", mu=0.0, shape=(q_size,))\n",
    "    std = pm.HalfNormal(\"std\", sd=1.0)\n",
    "\n",
    "    mu = b0 + theano.dot(model_input, b1)      \n",
    "    y_obs = pm.Normal(\"y_obs\", mu=mu, sd=std, observed=model_output) \n",
    "    \n",
    "minibatch_tensors = [model_input, model_output]\n",
    "\n",
    "draws = 10000*5\n",
    "with model:\n",
    "    sgfs_step_method = pm.step_methods.SGFS(vars=model.vars,\n",
    "                                            step_size=0.1,\n",
    "                                            step_size_decay=1000,\n",
    "                                            total_size=N,\n",
    "                                            batch_size=batch_size,\n",
    "                                            minibatches=minibatches, \n",
    "                                            minibatch_tensors=minibatch_tensors)  \n",
    "    sgfs_trace = pm.sample(draws=draws, step=sgfs_step_method, tune=500, init='map')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUTS Trace Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(nuts_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preconditioned CSG Trace Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(csg_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGFS Trace Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(sgfs_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace shared variables with testing set\n",
    "model_input.set_value(test_X)\n",
    "model_output.set_value(test_Y)\n",
    "\n",
    "samples = 1000\n",
    "\n",
    "# Creater posterior predictive samples\n",
    "sgfs_ppc = pm.sample_posterior_predictive(sgfs_trace, model=model, samples=samples, random_seed=0)\n",
    "sgfs_pred = sgfs_ppc['y_obs'].mean(axis=0)\n",
    "\n",
    "# Creater posterior predictive samples\n",
    "csg_ppc = pm.sample_posterior_predictive(csg_trace, model=model, samples=samples, random_seed=0)\n",
    "csg_pred = csg_ppc['y_obs'].mean(axis=0)\n",
    "\n",
    "# Nuts predictive samples\n",
    "nuts_ppc = pm.sample_posterior_predictive(nuts_trace, model=model, samples=samples, random_seed=0)\n",
    "nuts_pred = nuts_ppc['y_obs'].mean(axis=0)\n",
    "\n",
    "sgfs_diff = sgfs_pred-test_Y\n",
    "csg_diff = csg_pred-test_Y\n",
    "nuts_diff = nuts_pred-test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The NUTS Mean Absolute Error is {}'.format(np.sum(np.abs(nuts_diff))/test_Y.size))\n",
    "print('The CSG Mean Absolute Error is {}'.format(np.sum(np.abs(csg_diff))/test_Y.size))\n",
    "print('The SGFS Mean Absolute Error is {}'.format(np.sum(np.abs(sgfs_diff))/test_Y.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean absolute error for all the sampling algorithms is ~ 0.706. which is very close to the ols map fit\n",
    "0.7057. The error is slightly better using SGFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "sns.tsplot(data=nuts_diff, ax=ax, color=\"r\", interpolate=False, alpha=0.3)\n",
    "sns.tsplot(data=csg_diff, ax=ax, color=\"g\", interpolate=False, alpha=0.3)\n",
    "sns.tsplot(data=sgfs_diff, ax=ax, color=\"b\", interpolate=False, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample covariance projections on the smallest and largest components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_covariance(step_method, trace):\n",
    "    bij = pm.DictToArrayBijection(step_method.ordering, step_method.model.test_point)\n",
    "    q_size = bij.map(step_method.model.model.test_point).size\n",
    "    sample_size = len(trace)\n",
    "    posterior = np.empty((q_size, sample_size))\n",
    "    for index, point in enumerate(trace):\n",
    "        posterior[:, index] = bij.map(point)\n",
    "    posterior_minus_mean = posterior - np.asmatrix(posterior.mean(axis=1)).T\n",
    "    normalized_posterior = posterior_minus_mean / np.asmatrix(posterior.std(axis=1)).T\n",
    "    cov = np.matmul(normalized_posterior, normalized_posterior.T)\n",
    "    return posterior_minus_mean, cov\n",
    "\n",
    "def projection(posterior, cov):\n",
    "    U, S, V_h = np.linalg.svd(a=cov, compute_uv=True, full_matrices=True)\n",
    "    first_projection = V_h[0, :]\n",
    "    last_projection = V_h[-1, :]\n",
    "    q_size, samples = posterior.shape\n",
    "    projection_matrix = np.empty((samples, 2))\n",
    "    for i in range(samples):\n",
    "        projection_matrix[i, 0] = np.matmul(first_projection, posterior_minus_mean[:, i])\n",
    "        projection_matrix[i, 1] = np.matmul(last_projection, posterior_minus_mean[:, i])\n",
    "    return projection_matrix\n",
    "\n",
    "burn_in = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Between CSG and NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "posterior_minus_mean, cov = posterior_covariance(csg_step_method, nuts_trace[burn_in:])\n",
    "projection_matrix = projection(posterior_minus_mean, cov)\n",
    "df_nuts = pd.DataFrame(projection_matrix, columns=['X', 'Y'])\n",
    "ax.scatter(x=df_nuts['X'], y=df_nuts['Y'], s=0.5, alpha=0.1, c='r')\n",
    "\n",
    "posterior_minus_mean, cov = posterior_covariance(csg_step_method, csg_trace[burn_in:])\n",
    "projection_matrix = projection(posterior_minus_mean, cov)\n",
    "df_csg = pd.DataFrame(projection_matrix, columns=['X', 'Y'])\n",
    "ax.scatter(x=df_csg['X'], y=df_csg['Y'], s=0.5, alpha=0.1, c='g')\n",
    "\n",
    "\n",
    "ax.set_title(\"Stationary sampling distributions of the iterates of CSG and NUTS\", fontsize=20, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Between SGFS and NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "posterior_minus_mean, cov = posterior_covariance(csg_step_method, nuts_trace[burn_in:])\n",
    "projection_matrix = projection(posterior_minus_mean, cov)\n",
    "df_nuts = pd.DataFrame(projection_matrix, columns=['X', 'Y'])\n",
    "ax.scatter(x=df_nuts['X'], y=df_nuts['Y'], s=0.5, alpha=0.2, c='r')\n",
    "\n",
    "posterior_minus_mean, cov = posterior_covariance(sgfs_step_method, sgfs_trace[burn_in:])\n",
    "projection_matrix = projection(posterior_minus_mean, cov)\n",
    "df_sgfs = pd.DataFrame(projection_matrix, columns=['X', 'Y'])\n",
    "ax.scatter(x=df_sgfs['X'], y=df_sgfs['Y'], s=0.5, alpha=0.2, c='b')\n",
    "\n",
    "ax.set_title(\"stationary sampling distributions of the iterates of SGFS and NUTS\", fontsize=20, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constant Stochastic Gradient is a good approximator of the posterior, as can be seen from the trace plots and the projections of its sample covariance matrix which \n",
    "largely overlap with NUTS. The paper also presents a figure which shows large overlap between the true posterior and the constant stochastic gradient iteratre distribution. In comparison SGFS has a unique distribution, which shows a different relationship between the two components."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
