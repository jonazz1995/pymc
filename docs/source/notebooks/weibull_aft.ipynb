{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reparameterizing the Weibull Accelerated Failure Time Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import patsy\n",
    "import theano.tensor as tt\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [previous example notebook on Bayesian parametric survival analysis](https://docs.pymc.io/notebooks/bayes_param_survival.html) introduced two different accelerated failure time (AFT) models: Weibull and log-linear. In this notebook, we will explore three different versions/parameterizations of the Weibull AFT model.\n",
    "\n",
    "The data set we'll use is the `flchain` R data set, which comes from a medical study investigating the effect of serum free light chain (FLC) on lifespan. Read the full documentation of the data by running:\n",
    "\n",
    "`print(statsmodels.datasets.get_rdataset(package='survival', dataname='flchain').__doc__)`.\n",
    "\n",
    "Here, we are interested in seeing what effect, if any, the `age` and `sex` covariates have on the survival times of subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and clean data\n",
    "data = (statsmodels.datasets\n",
    "                   .get_rdataset(package='survival', dataname='flchain')\n",
    "                   .data\n",
    "                   .sample(500)  # Limit ourselves to 500 observations\n",
    "                   .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matrices of covariates from dataframe using patsy\n",
    "_, X_df = patsy.dmatrices(\"death ~ age + sex\", data, return_type='dataframe')\n",
    "X_df = X_df.iloc[:, X_df.columns != 'Intercept']\n",
    "\n",
    "# `X` contains covariates, `y` contains survival times, and\n",
    "# `censored` contains whether or not the survival time has been censored\n",
    "X = X_df.values\n",
    "y = data.futime.values\n",
    "censored = ~data['death'].values.astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `pm.Potential`\n",
    "\n",
    "We have an unique problem when modelling censored data. Strictly speaking, we don't have any _data_ for censored values: we only know the _number_ of values that were censored! How can we include this information in our model?\n",
    "\n",
    "One way do this is by making use of `pm.Potential`. The [PyMC2 docs](https://pymc-devs.github.io/pymc/modelbuilding.html#the-potential-class) explain it's use very well. Essentially, declaring `pm.Potential('x', logp)` will add `logp` to the log-likelihood of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "[(Source)](https://discourse.pymc.io/t/weibull-survival-regression-aft/1107/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_lccdf(x, alpha, beta):\n",
    "    ''' Log complementary cdf of Weibull distribution. '''\n",
    "    return -(x / beta)**alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_1:\n",
    "    alpha_sd = 10.0\n",
    "\n",
    "    mu = pm.Normal('mu', mu=0, sd=100)\n",
    "    alpha_raw = pm.Normal('a0', mu=0, sd=0.1)\n",
    "    alpha = pm.Deterministic('alpha', tt.exp(alpha_sd * alpha_raw))\n",
    "    beta = pm.Deterministic('beta', tt.exp(mu / alpha))\n",
    "    \n",
    "    y_obs = pm.Weibull('y_obs', alpha=alpha, beta=beta, observed=y[~censored])\n",
    "    y_cens = pm.Potential('y_cens', weibull_lccdf(y[censored], alpha, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_1:\n",
    "    # Increase tune and change init to avoid divergences\n",
    "    trace_1 = pm.sample(draws=1000, tune=1000,\n",
    "                        nuts_kwargs={'target_accept': 0.9},\n",
    "                        init='adapt_diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace_1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.summary(trace_1).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "\n",
    "[(Source)](https://github.com/stan-dev/example-models/blob/master/bugs_examples/vol1/kidney/kidney.stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_2:\n",
    "    alpha = pm.Normal('alpha', mu=0, sd=10)\n",
    "    r = pm.Gamma('r', alpha=1, beta=0.001, testval=0.25)\n",
    "    beta = pm.Deterministic('beta', tt.exp(-alpha / r))\n",
    "\n",
    "    y_obs = pm.Weibull('y_obs', alpha=r, beta=beta, observed=y[~censored])\n",
    "    y_cens = pm.Potential('y_cens', weibull_lccdf(y[censored], r, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with model_2:\n",
    "    # Increase tune and target_accept to avoid divergences\n",
    "    trace_2 = pm.sample(draws=1000, tune=1000,\n",
    "                        nuts_kwargs={'target_accept': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pm.traceplot(trace_2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace_2).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "[(Source)](http://austinrochford.com/posts/2017-10-02-bayes-param-survival.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logtime = np.log(y)\n",
    "\n",
    "def gumbel_sf(y, mu, sigma):\n",
    "    ''' Gumbel survival function. '''\n",
    "    return 1.0 - tt.exp(-tt.exp(-(y - mu) / sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_3:\n",
    "    s = pm.HalfNormal('s', tau=5.0)\n",
    "    gamma = pm.Normal('gamma', mu=0, sd=5)\n",
    "\n",
    "    y_obs = pm.Gumbel('y_obs', mu=gamma, beta=s, observed=logtime[~censored])\n",
    "    y_cens = pm.Potential('y_cens', gumbel_sf(y=logtime[censored], mu=gamma, sigma=s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_3:\n",
    "    trace_3 = pm.sample(draws=1000, tune=1000,\n",
    "                        init='adapt_diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace_3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.summary(trace_3).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Originally researched by [Junpeng Lao](https://junpenglao.xyz/) on Apr 21, 2018. See original code [here](https://github.com/junpenglao/Planet_Sakaar_Data_Science/blob/65447fdb431c78b15fbeaef51b8c059f46c9e8d6/PyMC3QnA/discourse_1107.ipynb).\n",
    "- Authored and ported to Jupyter notebook by [George Ho](https://eigenfoo.xyz/) on Jul 15, 2018."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
